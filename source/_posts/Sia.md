---
layout: fast
title: Sia-考虑集群异构性和作业弹性的DL训练系统
date: 2025-01-16 14:22:46
summary: 
cover: posts_img/Sia/4.png
categories: 
  - Paper Report
tags: 
  - SOSP 2023
  - DL
  - Train
  - Mlsys
  - Heterogeneity
---

Sia 调度器结合**Gavel**和**Pollux**这两篇文章的优势，提出了一种为**异构**深度学习集群的**弹性**资源自适应作业提供高效资源分配的方法，解决了现有调度器在异构性和资源适应性上的不足。Sia 使用**Bootstrapping + 在线优化**的方法，低开销、快速评估作业在不同配置下的性能，接着使用**ILP算法**进行资源分配，能够在大规模集群中高效扩展，并根据集群负载和作业需求动态调整。Sia 是首个支持混合并行作业弹性扩展的集群调度器。广泛的实验表明，Sia 在多个工作负载环境中显著提高了作业完成效率和资源利用率，并且具有良好的扩展性和公平性，能够支持高达 2000 GPU 的集群。

论文：(SOSP 2023)[Sia: Heterogeneity-aware, goodput-optimized ML-cluster scheduling](https://suhasjs.github.io/files/sia-sosp23.pdf)

代码：https://github.com/siasosp23/artifacts

# 研究背景及内容
深度学习模型的训练和推理，对计算资源的要求极为庞大，对于普通企业和用户而言部署的成本巨大，基于此背景，各大企业的深度学习云计算平台应运而生。

![](posts_img/Sia/1.png)


用户会将深度学习模型部署到云端，进行训练或推理作业，通常会请求一定的计算资源，以保证自己对任务在时间和精度上的的需求。集群调度器决定如何将资源分配给任务，以实现公平调度、最小化任务完成时间(JCT)、提高集群利用率等目标。

![](posts_img/Sia/2.png)

现有的调度器在优化资源分配、减少作业完成时间 (JCT) 以及提高 GPU 利用率方面存在局限性：

![](posts_img/Sia/3.png)

在Sia这篇论文中，作者考虑的场景是DL任务的训练调度，的优化目标是最小化作业的JCT。过去有很多工作考虑弹性调度或者GPU资源的异构，但是没有综合两者进行考虑，其中考虑资源异构的SOTA是Gavel，考虑弹性调度的SOTA是Pollux。作者提出 Sia 调度器，结合异构性与弹性，在实际场景中优化集群资源调度。

# 研究方法及过程

Sia特点：

1. Sia是一个基于抢占式、轮询的调度器。

2. 使用低开销的方法来引导（bootstrap）每个新作业的吞吐量模型，这些模型用于评估可能的资源分配。

3. 通过引入一种新的调度公式来解决大规模搜索空间的问题，将作业及其配置与 GPU 类型和数量匹配，同时适应集群负载和作业组合的变化。 

![**Sia 中作业的生命周期**](posts_img/Sia/4.png)

作业提交后，它会在每种 GPU 类型上对几个批次大小进行一次profiling分析。获得资源分配后，作业开始进入一个持续优化的周期（步骤 5-8），持续进行直到它在集群中的生命周期结束。**Policy** 用于 ILP 问题求解，会不断优化作业的分配；**Adaptive Executors** 支持动态调整作业运行配置，如batch size； **Goodput Estimator** 提供最新的性能和梯度统计数据，以帮助决策。

作业在提交后进行快速初始配置建模，并周期性地重新分配资源以实现动态优化。

我认为，Sia这篇文章主要回答了以下三个问题。

## Q1. 异构集群中，作业的性能因 GPU 类型和数量变化而异，如何高效建模？

答：引入Goodput Estimator模块，使用**Bootstrapping + 在线优化**的方法高效建模。

![](posts_img/Sia/5.png)

- 初始profiling建模时最大限度减少开销。
- 启发式推断未运行 GPU 类型的多 GPU 配置性能。
- 在线学习逐步精确吞吐量模型。


## Q2. 作业的动态弹性扩展（GPU 数量）带来巨大搜索空间，如何降低调度开销？

答：在Policy算法中构造配置集合，减小搜索空间。

![](posts_img/Sia/6.png)

Sia 将配置集合 𝐶 分为两部分：

- 单节点配置（Single-node set）: 包含所有在单个节点上的资源分配。约束为 GPU 数量必须是 2 的幂，且最多不超过每节点的 GPU 数量 𝑅。如果 𝑅 不是 2 的幂，可以将节点视为多个虚拟节点。
- 多节点配置（Multi-node set）: 包含跨多个节点的资源分配。约束为 GPU 数量必须是每节点 GPU 数量 𝑅 的整数倍（确保使用完整节点）。

Sia 利用子网形状覆盖定理（{% post_link 'Alpa-自动生成DL/LLM模型并行策略' %}这篇文章证明的），确保所有配置的资源分配是有效的，同时避免多个作业共享节点，减少网络接口（NIC）的资源争用。

与 Pollux 的对比
- **Pollux**: 在资源分配中优化整个搜索空间（即 GPU 数量 × GPU 放置组合），其复杂度为 O(N^R)，其中 N 是节点数，R 是每节点 GPU 数量。
- **Sia**: 限制配置集合大小，单节点配置数量为 log₂ R，多节点配置数量为 N，因此总体复杂度为 N + log₂ R。通过限制搜索空间，显著减少了问题复杂度，同时性能与 Pollux 相当。

## Q3. 如何设计调度算法提高集群效率（作业完成时间）？

答：**有效吞吐量评估 + 整数线性规划**。

Sia 使用 goodput 来衡量作业在特定配置下的效率，使得作业在不同 GPU 类型和数量上的效能具有可比性。

![](posts_img/Sia/7.png)

Goodput根据吞吐量和统计效率得到，用来衡量作业每秒的进度。定义详见Pollux这篇文章。

### Goodput 矩阵 G

基于最小 goodput 值归一化 Goodput 矩阵：行内值可直接比较，反映每个作业在不同配置下的效用。列间值也可比较，用于评估配置对不同作业的优先级。

![](posts_img/Sia/8.png)

Sia 为每个作业的每种配置计算出相应的 goodput ，并通过归一化的方式使得其既能根据给定作业选择最适合的配置，又能根据给定配置选择最适合的作业。

Sia 会一直维护这个矩阵，当新的作业到来时，会在矩阵中添加新的一行。旧的作业完成时，会删除其相应的行。使得 goodput 矩阵一直保持在最新状态，仅适用于活动中的作业。

### 整数线性规划（ILP）

![](posts_img/Sia/9.png)

- **动态性**: 矩阵 G 实时更新，随着作业的统计效率变化或模型改进不断优化分配决策。
- **资源高效利用**: 优化目标结合 goodput 和作业等待惩罚，确保资源高效分配。
- **扩展性**: 使用 ILP 求解，能够快速计算大规模集群的优化分配方案。

基于这个ILP，论文中还提到了许多优化方案：
- 重启因子 (Restart Factor)
- 公平性调节 (Balancing Goodput and Fairness)
- 混合并行训练 (Hybrid-parallel training)
- 抢占和预留机制 (Preemption and reservation)
- 其他非GPU工作负载的调度 (Other types of workloads)
- …

# 实验与分析

## 调度中的自适应表现

![](posts_img/Sia/10.png)

- Sia具有良好的自适应性，能够动态调整分配给每个作业的GPU数量和类型。
- Bootstrapping确实能够快速地为作业匹配GPU类型。

矩形之间的空格是Sia调度的延迟

## 调度性能实验

### 实验设置

#### 集群配置
- 异构 GPU 集群，包括 T4、V100 和 A100 等不同 GPU 类型。
- 集群规模从几十个到上千个 GPU 节点。

#### 工作负载
使用真实生产集群工作负载，包括：
- **Philly**：微软 GPU 集群的深度学习工作负载。
- **Helios**：基于大规模高负载环境的仿真工作负载。
- **newTrace**：实际深度学习训练任务的动态工作负载。

#### 对比调度器
- **Pollux**：专注于作业弹性扩展的调度器。
- **Gavel**：优化异构资源分配的调度器。

![](posts_img/Sia/11.png)

**平均 JCT 改善**
 - 在 Philly 数据集中，平均 JCT 比 Pollux 和 Gavel 分别减少 30%-93%。
 - 在 Helios 数据集中，99 分位数 JCT 减少了 50%-80%。

![](posts_img/Sia/12.png)

**GPU 小时数节省**
- 在 Helios 工作负载中，GPU 小时数减少 12%-60%。

## 算法效率实验

![](posts_img/Sia/13.png)

Sia具有良好的扩展性，Pollux的遗传算法运行速度明显较慢（比Sia的ILP公式慢100倍），Gavel要快得多，因为它没有考虑工作适应。

# 总结与展望
## 总结
1. **联合优化异构性与作业弹性**
 
   支持弹性扩展和异构 GPU 混合调度。

2. **动态吞吐量建模**
 
   引入轻量级的在线学习机制，通过少量配置样本快速预测作业性能。快速适应作业需求和资源需求，有效支持异构 GPU 类型和动态负载。

3. **高效集群、扩展性与适配性**
   
   支持大规模集群（上千 GPU）的高效调度，支持多种任务类型，任务并行方式、平衡公平性与效率。

## 展望
1. 支持更复杂的混合并行任务调度（如流水线并行与数据并行结合）。
2. 在超大规模集群（2000+ GPU）中进一步验证性能。
3. 优化对其他类型工作负载（如实时推理任务）的支持。